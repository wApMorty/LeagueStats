# Plan d'Action - OfflineFirstDataSource

**Date de cr√©ation** : 2026-02-07
**Objectif** : Passer d'une architecture API-first √† Offline-first
**Approche** : Approche 2 - OfflineFirstDataSource d√©di√©e (recommand√©e par Architecte)

## üéØ Vue d'Ensemble

**Architecture Cible** :
- **Offline-first** : Utiliser SQLite par d√©faut (rapide, fiable, 0ms latency)
- **Refresh intelligent** : Si donn√©es > 24h ‚Üí T√©l√©charger depuis API et remplacer SQLite
- **Fallback gracieux** : Si API √©choue ‚Üí Continuer avec SQLite existante
- **Auto-update inchang√©** : Script continue scraping ‚Üí SQLite, mais met √† jour timestamp

**Estimation** : 11-15 heures de d√©veloppement (11 t√¢ches en 4 phases)

---

## üìã Les 11 T√¢ches

### Phase 1 - Foundation (2-3h)

#### T√¢che #1 : Migration Alembic table metadata
- **Expert** : database-expert
- **D√©pendances** : Aucune ‚úÖ PR√äTE
- **Fichier √† cr√©er** : `alembic/versions/XXXXXX_add_metadata_table.py`
- **Schema** :
  ```sql
  CREATE TABLE metadata (
      key TEXT PRIMARY KEY,
      value TEXT NOT NULL,
      updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
  );
  ```
- **Validation** :
  - `alembic upgrade head` passe
  - Table metadata existe avec schema correct
  - Migration r√©versible (downgrade fonctionne)

#### T√¢che #2 : M√©thodes metadata dans src/db.py
- **Expert** : python-expert
- **D√©pendances** : #1
- **Fichier √† modifier** : `src/db.py`
- **M√©thodes √† ajouter** :
  - `get_metadata(key: str) -> Optional[str]`
  - `set_metadata(key: str, value: str) -> None`
  - `replace_all_data(champions, matchups, synergies) -> None`
  - `_ensure_metadata_table_exists() -> None` (backward compatibility)
- **Validation** :
  - Type hints sur toutes m√©thodes
  - Requ√™tes SQL param√©tr√©es
  - Transaction atomique pour replace_all_data
  - Backward compatibility (BD sans metadata)

#### T√¢che #3 : M√©thodes metadata dans src/sqlite_data_source.py
- **Expert** : python-expert
- **D√©pendances** : #2
- **Fichier √† modifier** : `src/sqlite_data_source.py`
- **M√©thodes √† ajouter** :
  - `get_last_sync_timestamp() -> Optional[datetime]`
  - `update_last_sync_timestamp(timestamp: datetime) -> None`
  - `replace_all_data(champions, matchups, synergies) -> None`
- **Validation** :
  - Pure delegation (Adapter Pattern)
  - Format datetime ISO 8601
  - Tests avec mocks Database

---

### Phase 2 - Core Logic (4-5h)

#### T√¢che #4 : Module metadata_manager.py
- **Expert** : python-expert
- **D√©pendances** : #2
- **Fichier √† cr√©er** : `src/utils/metadata_manager.py`
- **Fonctions √† ajouter** :
  - `get_last_sync_timestamp(db: Database) -> Optional[datetime]`
  - `update_last_sync_timestamp(db: Database, timestamp: datetime) -> None`
  - `is_data_stale(db: Database, threshold_hours: int = 24) -> bool`
- **Validation** :
  - Type hints + docstrings compl√®tes
  - Gestion erreurs (format invalide, BD sans metadata)
  - Tests unitaires 100% coverage

#### T√¢che #5 : M√©thode download_all_data_bulk dans API
- **Expert** : python-expert
- **D√©pendances** : Aucune ‚úÖ PR√äTE
- **Fichier √† modifier** : `src/api_data_source.py`
- **M√©thode √† ajouter** :
  - `download_all_data_bulk() -> Dict[str, List]`
  - Retourne : `{"champions": [...], "matchups": [...], "synergies": [...]}`
- **Endpoints utilis√©s** :
  - `GET /api/champions`
  - `GET /api/matchups/bulk`
  - `GET /api/synergies/bulk`
- **Validation** :
  - Timeout 300s (5 min)
  - Retry logic (3 tentatives)
  - Logging progression
  - Exceptions propag√©es pour fallback

#### T√¢che #6 : Classe OfflineFirstDataSource
- **Expert** : python-expert
- **D√©pendances** : #3, #4, #5
- **Fichier √† cr√©er** : `src/offline_first_data_source.py`
- **Classe** : `OfflineFirstDataSource(DataSource)`
- **M√©thodes cl√©s** :
  - `__init__(database_path, api_base_url)`
  - `connect() -> None` (v√©rifie staleness + refresh si n√©cessaire)
  - `_download_and_replace_data() -> None` (download API + remplace SQLite)
  - Toutes m√©thodes DataSource : D√©l√®gue √† SQLiteDataSource
- **Validation** :
  - Composition SQLiteDataSource + APIDataSource
  - Graceful fallback si API √©choue
  - Logging verbeux
  - Tests refresh + fallback

---

### Phase 3 - Integration (2-3h)

#### T√¢che #7 : Config OfflineFirstConfig
- **Expert** : python-expert
- **D√©pendances** : Aucune ‚úÖ PR√äTE
- **Fichier √† modifier** : `src/config_constants.py`
- **Config √† ajouter** :
  ```python
  @dataclass
  class OfflineFirstConfig:
      ENABLED: bool = True
      REFRESH_THRESHOLD_HOURS: int = 24
      AUTO_REFRESH_ON_CONNECT: bool = True
      FALLBACK_TO_CACHED: bool = True
  ```
- **Validation** :
  - Docstring compl√®te
  - Valeurs par d√©faut sens√©es
  - Backward compatible avec HybridDataSource

#### T√¢che #8 : Modifier Assistant pour OfflineFirstDataSource
- **Expert** : python-expert
- **D√©pendances** : #6, #7
- **Fichier √† modifier** : `src/assistant.py`
- **Changements** :
  - Import OfflineFirstDataSource + offline_first_config
  - Modifier `__init__()` logique s√©lection data source
  - Mettre √† jour docstring Assistant (nouveau mode)
- **Validation** :
  - Backward compatibility HybridDataSource
  - Tests Assistant avec OfflineFirstDataSource
  - Docstring claire sur modes

#### T√¢che #9 : Modifier auto_update_db.py pour timestamp
- **Expert** : python-expert
- **D√©pendances** : #4
- **Fichier √† modifier** : `scripts/auto_update_db.py`
- **Changements** :
  - Import metadata_manager
  - Appeler `update_last_sync_timestamp()` apr√®s scraping r√©ussi
  - Ligne ~420 (apr√®s recalcul scores)
- **Validation** :
  - Timestamp mis √† jour UNIQUEMENT si succ√®s
  - Format ISO 8601
  - Logging clair
  - Tests manuels `SELECT * FROM metadata`

---

### Phase 4 - Testing (3-4h)

#### T√¢che #10 : Tests OfflineFirstDataSource
- **Expert** : qa-expert
- **D√©pendances** : #6
- **Fichier √† cr√©er** : `tests/test_offline_first_data_source.py`
- **Tests √† cr√©er** :
  - `test_connect_with_fresh_data` (pas de refresh)
  - `test_connect_with_stale_data` (refresh d√©clench√©)
  - `test_connect_with_api_failure_fallback`
  - `test_backward_compatibility_no_metadata`
  - `test_all_methods_delegate_to_sqlite`
- **Validation** :
  - Coverage >= 70% OfflineFirstDataSource
  - Mocks SQLiteDataSource + APIDataSource
  - `pytest tests/test_offline_first_data_source.py -v` passe

#### T√¢che #11 : Tests Assistant integration
- **Expert** : qa-expert
- **D√©pendances** : #8
- **Fichier √† modifier** : `tests/test_assistant_integration.py`
- **Tests √† ajouter** :
  - `test_assistant_uses_offline_first_by_default`
  - `test_assistant_offline_first_refresh_on_stale_data`
  - `test_assistant_backward_compatibility_hybrid`
- **Validation** :
  - Tests avec mocks (pas de BD/API r√©elle)
  - Coverage Assistant.__init__() augment√©
  - `pytest tests/test_assistant_integration.py -v` passe

---

## üîÑ Ordre d'Ex√©cution Recommand√©

### Vague 1 (parall√®le possible) - PR√äTES MAINTENANT
- ‚úÖ **#1** : Migration Alembic
- ‚úÖ **#5** : download_all_data_bulk API
- ‚úÖ **#7** : OfflineFirstConfig

### Vague 2 (apr√®s Vague 1)
- **#2** : M√©thodes Database (attend #1)

### Vague 3 (apr√®s Vague 2)
- **#3** : M√©thodes SQLiteDataSource (attend #2)
- **#4** : metadata_manager.py (attend #2)

### Vague 4 (apr√®s Vague 3)
- **#6** : OfflineFirstDataSource (attend #3, #4, #5)
- **#9** : auto_update_db (attend #4)

### Vague 5 (apr√®s Vague 4)
- **#8** : Modifier Assistant (attend #6, #7)
- **#10** : Tests OfflineFirstDataSource (attend #6)

### Vague 6 (finale)
- **#11** : Tests Assistant integration (attend #8)

---

## ‚úÖ Crit√®res de Succ√®s Final

L'impl√©mentation sera consid√©r√©e compl√®te quand :

### Fonctionnel
- ‚úÖ Donn√©es SQLite < 24h ‚Üí Utilise SQLite directement (0ms latency)
- ‚úÖ Donn√©es SQLite > 24h ‚Üí Download API + remplace SQLite atomiquement
- ‚úÖ API √©choue ‚Üí Continue avec SQLite (graceful fallback)
- ‚úÖ Auto-update met √† jour timestamp apr√®s scraping
- ‚úÖ Backward compatibility : Ancienne BD sans metadata ‚Üí Cr√©er table auto

### Technique
- ‚úÖ Toutes les 11 t√¢ches marqu√©es "completed"
- ‚úÖ Migration Alembic passe (`alembic upgrade head`)
- ‚úÖ Tous tests passent (`pytest tests/ -v`)
- ‚úÖ Formatage Black appliqu√© (`python -m black src/ tests/`)
- ‚úÖ Type hints sur toutes nouvelles fonctions
- ‚úÖ Coverage >= 70% sur nouvelles classes
- ‚úÖ Compilation Python OK (`python -m py_compile src/**/*.py`)

---

## üöÄ Comment Reprendre

### 1. Voir les t√¢ches restantes
```python
# Dans Claude Code
TaskList
```

### 2. Voir les d√©tails d'une t√¢che
```python
TaskGet(taskId="#1")
```

### 3. Spawner un expert pour une t√¢che
```bash
# Exemple pour t√¢che #1
/spawn database-expert

# Puis lui passer :
"Cr√©e la migration Alembic pour table metadata selon le plan de la t√¢che #1.
Voir OFFLINE_FIRST_PLAN.md pour les d√©tails."
```

### 4. Marquer une t√¢che compl√©t√©e
```python
TaskUpdate(taskId="#1", status="completed")
```

### 5. V√©rifier d√©blocage t√¢ches suivantes
```python
TaskList
```

---

## ‚ö†Ô∏è Risques et Mitigations

### Risque 1 : Download API lent (30-60s)
**Mitigation** : Timeout 5 min, logging progression, abandon si trop lent

### Risque 2 : Transaction SQLite peut bloquer DB (2-5s)
**Mitigation** : Transaction IMMEDIATE, logs clairs, tester performance

### Risque 3 : Ancienne BD sans table metadata
**Mitigation** : Cr√©er table auto au connect(), initialiser timestamp √† epoch 0

---

## üìö R√©f√©rences

- **Architecture compl√®te** : Voir output de l'Architecte (agent `adb7da5`)
- **Plan d√©taill√©** : Voir output du Tech Lead (agent `a29bdb6`)
- **Code existant** :
  - `src/hybrid_data_source.py` - Pattern API-first actuel
  - `src/api_data_source.py` - Client API HTTP
  - `scripts/sync_local_to_neon.py` - Pattern de transfert bulk (√† inverser)

---

**Derni√®re mise √† jour** : 2026-02-07 01:15 AM
**Status** : Plan cr√©√©, pr√™t pour impl√©mentation
