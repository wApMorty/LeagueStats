# TODO - League Stats Coach

## üéØ Backlog Prioris√© (M√©thode Agile)

**L√©gende Scores Fibonacci**:
- **Plus-value**: 1 (minime) ‚Üí 21 (critique pour le business)
- **Difficult√©**: 1 (trivial) ‚Üí 21 (tr√®s complexe)
- **ROI**: Plus-value / Difficult√© (ratio b√©n√©fice/effort)

---

## üìä Vue d'Ensemble des T√¢ches

**‚ö†Ô∏è APPROCHE: Dette Technique First** - Prioriser qualit√© et maintenabilit√©

| # | T√¢che | Plus-value | Difficult√© | ROI | Priorit√© | Statut |
|---|-------|------------|------------|-----|----------|--------|
| **2** | **Extraction valeurs hardcod√©es** | **8** | **3** | **2.67** | üî¥ | ‚úÖ **FAIT** |
| **1** | **Refactoring fichiers monolithiques** | **13** ‚¨ÜÔ∏è | **13** | **1.00** | üî¥üî¥üî¥ | ‚ùå **NEXT** |
| **5** | **Pool Statistics Viewer** | **5** | **3** | **1.67** | üü° | ‚ùå |
| **11** | **Auto-Update BD (Service Windows)** | **13** | **8** | **1.63** | üü° | ‚ùå |
| **4** | **Web Scraping parall√®le** | **13** | **8** | **1.63** | üü° | ‚ùå |
| **9** | **Migrations Base de Donn√©es** | **8** ‚¨ÜÔ∏è | **5** | **1.60** | üî¥ | ‚ùå |
| **10** | **CI/CD Pipeline** | **8** | **5** | **1.60** | üü¢ | ‚ùå |
| **3** | **Framework Tests Automatis√©s** | **13** | **13** | **1.00** | üî¥üî¥ | üü° Partiel |
| **12** | **Architecture Client-Serveur + Web App** | **21** | **34** | **0.62** | üü¢ | ‚ùå |
| **7** | **Support Multi-Plateformes** | **5** | **8** | **0.63** | üü¢ | ‚ùå |
| **6** | **Interface Graphique (GUI)** | **13** | **21** | **0.62** | üü¢ | ‚ùå |
| **8** | **Internationalisation (i18n)** | **3** | **5** | **0.60** | üü¢ | ‚ùå |

**‚¨ÜÔ∏è Changements scores (Dette Technique):**
- **T√¢che #1**: Plus-value 8‚Üí**13** (base saine pour TOUTES futures t√¢ches)
- **T√¢che #9**: Plus-value 5‚Üí**8** (infrastructure BD critique, √©vite pertes donn√©es)

**Recommandation Sprint**: **Dette Technique First** ‚Üí Refactoring + Tests + Migrations AVANT features

---

## üî¥ HAUTE PRIORIT√â - Sprint 1 (1-2 semaines)

### ‚≠ê T√¢che #2: Extraction des Valeurs Hardcod√©es
**Status**: ‚úÖ **FAIT** (2025-11-27)
**Effort**: 1 jour (8h)

**Scores Fibonacci**:
- üìà **Plus-value**: **8** (impact √©lev√© sur maintenabilit√©)
- üîß **Difficult√©**: **3** (facile - simple refactoring)
- üéØ **ROI**: **2.67** ‚≠ê **QUICK WIN**

**Pourquoi ce score**:
- **Plus-value = 8**: Permet configuration user-editable, facilite debug, √©vite bugs hardcoded
- **Difficult√© = 3**: Copier-coller de valeurs, pas de logique complexe

**Fichiers concern√©s**: `parser.py`, `assistant.py`, `draft_monitor.py`

**Valeurs √† extraire**:

```python
# Cr√©er: src/config_constants.py
from dataclasses import dataclass, field

@dataclass
class ScrapingConfig:
    COOKIE_BUTTON_DELAY: float = 0.3
    PAGE_LOAD_DELAY: int = 2
    SCRAPING_DELAY_BETWEEN_CHAMPIONS: int = 1
    RETRY_ATTEMPTS: int = 3
    TIMEOUT: int = 30

@dataclass
class AnalysisConfig:
    MIN_GAMES_THRESHOLD: int = 100
    MIN_PICKRATE_THRESHOLD: float = 0.5
    TIER_THRESHOLDS: dict = field(default_factory=lambda: {
        'S': 52, 'A': 50, 'B': 48, 'C': 46
    })

@dataclass
class DraftConfig:
    POLL_INTERVAL: float = 1.0
    AUTO_HOVER_DELAY: float = 0.5
    AUTO_BAN_ENABLED: bool = True

# Instances globales
scraping_config = ScrapingConfig()
analysis_config = AnalysisConfig()
draft_config = DraftConfig()
```

**Action**: D√©placer toutes ces valeurs dans `config.py` avec des classes dataclass.

**B√©n√©fices**:
- ‚úÖ Configuration centralis√©e
- ‚úÖ Valeurs modifiables sans toucher code
- ‚úÖ Validation des types avec dataclass
- ‚úÖ Documentation auto via IDE

---

### T√¢che #1: Refactoring des Fichiers Monolithiques
**Status**: ‚ùå Not started ‚Üí **PROCHAINE T√ÇCHE** üî¥üî¥üî¥
**Effort**: 2-3 jours (16-24h)

**Scores Fibonacci**:
- üìà **Plus-value**: **13** ‚¨ÜÔ∏è (dette technique - base saine pour TOUTES futures t√¢ches)
- üîß **Difficult√©**: **13** (complexe - risque de r√©gression)
- üéØ **ROI**: **1.00** (investissement n√©cessaire, approche Dette Technique First)

**Pourquoi ce score** (r√©vis√© pour Dette Technique First):
- **Plus-value = 13** (anciennement 8):
  - ‚úÖ **Impact multiplicateur**: Facilite TOUTES les futures t√¢ches (tests, features, refactoring)
  - ‚úÖ **√âvite dette compos√©e**: Refactorer maintenant √©vite refactoring complexe plus tard
  - ‚úÖ **Qualit√© long terme**: Navigation code, tests unitaires, onboarding, maintenabilit√©
  - ‚úÖ **Fondation solide**: Partir de bases propres = moins de bugs, plus de v√©locit√©
  - üìä **Raisonnement**: Refactorer 2 jours MAINTENANT √©vite 5-10 jours de refactoring PLUS TARD
- **Difficult√© = 13**: Touche beaucoup de code, risque r√©gression, imports complexes, tests exhaustifs requis

**Probl√®me**: `lol_coach.py` (2,160 lignes) et `assistant.py` (2,381 lignes) sont trop grands.

**Plan de refactoring**:

```
src/
‚îú‚îÄ‚îÄ ui/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ menu_system.py        # Syst√®me de menus principal
‚îÇ   ‚îú‚îÄ‚îÄ draft_ui.py            # Interface draft coach
‚îÇ   ‚îú‚îÄ‚îÄ tournament_ui.py       # Interface tournoi
‚îÇ   ‚îú‚îÄ‚îÄ pool_ui.py             # Interface pool manager
‚îÇ   ‚îî‚îÄ‚îÄ stats_ui.py            # Interface stats & parsing
‚îú‚îÄ‚îÄ analysis/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ scoring.py             # Algorithmes de score
‚îÇ   ‚îú‚îÄ‚îÄ tierlist.py            # G√©n√©ration tier lists
‚îÇ   ‚îú‚îÄ‚îÄ optimizer.py           # Optimisation √©quipes (trios/duos)
‚îÇ   ‚îî‚îÄ‚îÄ recommendations.py     # Syst√®me de recommandations
‚îî‚îÄ‚îÄ core/
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îî‚îÄ‚îÄ assistant.py           # Classe Assistant simplifi√©e
```

**√âtapes**:
1. Cr√©er structure de r√©pertoires
2. Extraire logique UI de `lol_coach.py` ‚Üí `src/ui/`
3. Extraire algorithmes de `assistant.py` ‚Üí `src/analysis/`
4. Mettre √† jour imports
5. **CRITIQUE**: Tester toutes les fonctionnalit√©s apr√®s chaque √©tape
6. Supprimer code dupliqu√©

**B√©n√©fices**:
- Code plus navigable
- Facilite les tests unitaires
- R√©utilisation du code
- Onboarding plus facile

**‚ö†Ô∏è Attention**: N√©cessite tests exhaustifs pour √©viter r√©gressions

---

## üü° PRIORIT√â MOYENNE - Sprint 2 (2-3 semaines)

### ‚≠ê T√¢che #4: Am√©lioration du Web Scraping
**Status**: ‚ùå Not started
**Effort**: 1-2 jours (8-16h)

**Scores Fibonacci**:
- üìà **Plus-value**: **13** (gain temps utilisateur massif)
- üîß **Difficult√©**: **8** (mod√©r√© - threading + retry logic)
- üéØ **ROI**: **1.63** ‚≠ê **HAUTE VALEUR**

**Pourquoi ce score**:
- **Plus-value = 13**: Parsing 30-60min ‚Üí 6-8min = **80% plus rapide** üöÄ
- **Difficult√© = 8**: ThreadPoolExecutor pas trivial, risque rate-limiting

**Probl√®mes actuels**:
- ‚ùå Parsing s√©quentiel (30-60 min pour tous les champions)
- ‚ùå Coordonn√©es hardcod√©es pour cookies ‚Üí Bug #1
- ‚ùå Pas de retry logic
- ‚ùå Pas de rate limiting

**Am√©liorations**:

```python
from concurrent.futures import ThreadPoolExecutor
from tenacity import retry, stop_after_attempt, wait_exponential

# 1. Scraping parall√®le
def scrape_champions_parallel(champions, max_workers=5):
    """Scrape multiple champions in parallel with ThreadPoolExecutor."""
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        results = list(executor.map(scrape_champion, champions))
    return results

# 2. Retry avec exponential backoff
@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
def scrape_champion_with_retry(champion):
    """Scrape champion with automatic retry on failure."""
    return scrape_champion_internal(champion)

# 3. Gestion dynamique cookies (FIX Bug #1)
def accept_cookies_dynamic(driver):
    """Accept cookies without hardcoded coordinates."""
    try:
        # Essayer plusieurs s√©lecteurs communs
        selectors = [
            "onetrust-accept-btn-handler",
            "cookie-accept",
            "accept-cookies"
        ]
        for selector_id in selectors:
            try:
                button = driver.find_element(By.ID, selector_id)
                button.click()
                return True
            except:
                continue

        # Fallback: chercher par texte
        button = driver.find_element(By.XPATH, "//button[contains(text(), 'Accept')]")
        button.click()
        return True
    except:
        print("[WARNING] Could not find cookie acceptance button")
        return False
```

**Gains estim√©s**:
- ‚è±Ô∏è Temps: 30-60 min ‚Üí **6-8 min** (80% r√©duction)
- üêõ Bugs: Correction Bug #1 (coordonn√©es hardcod√©es)
- üîÑ Fiabilit√©: Retry automatique sur √©checs

**D√©pendance**: Installer `tenacity` dans requirements.txt

---

### T√¢che #3: Framework de Tests Automatis√©s
**Status**: üü¢ Partiellement commenc√© (`test_db_fixes.py` existe)
**Effort**: 3-5 jours (24-40h)

**Scores Fibonacci**:
- üìà **Plus-value**: **13** (qualit√© et confiance code)
- üîß **Difficult√©**: **13** (complexe - couverture 70%+)
- üéØ **ROI**: **1.00** (investissement n√©cessaire)

**Pourquoi ce score**:
- **Plus-value = 13**: Pr√©vient r√©gressions, facilite refactoring, confiance d√©ploiement
- **Difficult√© = 13**: √âcrire 70% tests = beaucoup de code, mocks complexes

**Objectif**: Passer de **5% ‚Üí 70%+ couverture**

**Structure propos√©e**:

```
tests/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ conftest.py                    # Fixtures pytest
‚îú‚îÄ‚îÄ test_database.py               # Tests db.py (FAIT ‚úÖ)
‚îú‚îÄ‚îÄ test_assistant_scoring.py     # Tests algorithmes scoring
‚îú‚îÄ‚îÄ test_tierlist.py               # Tests g√©n√©ration tier lists
‚îú‚îÄ‚îÄ test_optimizer.py              # Tests optimal trios/duos
‚îú‚îÄ‚îÄ test_pool_manager.py           # Tests champion pools
‚îú‚îÄ‚îÄ test_lcu_client.py             # Tests (mocks) LCU
‚îî‚îÄ‚îÄ test_parser.py                 # Tests (mocks) web scraping
```

**Priorit√©s de tests** (par ordre):
1. ‚úÖ **Database** - FAIT (test_db_fixes.py)
2. ‚≠ê **Assistant scoring** - Critique (calculs winrate, delta2)
3. üéØ **Tier list generation** - Important (normalisation, seuils)
4. üéØ **Pool manager** - Moyen (CRUD operations)
5. üîß **LCU client** - Bas (avec mocks)

**Commandes**:
```bash
pip install pytest pytest-cov pytest-mock
pytest tests/ -v --cov=src --cov-report=html
open htmlcov/index.html  # Voir rapport couverture
```

**Exemple test scoring**:
```python
# tests/test_assistant_scoring.py
import pytest
from src.assistant import Assistant

@pytest.fixture
def assistant(tmp_path):
    """Fixture pour Assistant avec DB temporaire."""
    db_path = tmp_path / "test.db"
    return Assistant(db_path)

def test_calculate_counter_score_basic(assistant):
    """Test calcul score counter simple."""
    # Arrange
    enemy_delta2 = 2.5

    # Act
    score = assistant.calculate_counter_score(enemy_delta2)

    # Assert
    assert score > 50  # Champion favorable contre ennemi
    assert 0 <= score <= 100  # Score normalis√©

def test_tier_list_thresholds(assistant):
    """Test que les seuils tier list sont corrects."""
    # Test qu'un champion avec 53% winrate ‚Üí Tier S
    tier = assistant.calculate_tier(53.0)
    assert tier == 'S'
```

**B√©n√©fices**:
- ‚úÖ D√©tection r√©gressions automatique
- ‚úÖ Refactoring en confiance
- ‚úÖ Documentation vivante du code
- ‚úÖ CI/CD possible

---

### ‚≠ê T√¢che #5: Pool Statistics Viewer
**Status**: ‚ùå Not started
**Effort**: 1 jour (8h)

**Scores Fibonacci**:
- üìà **Plus-value**: **5** (insight utile mais non critique)
- üîß **Difficult√©**: **3** (facile - r√©utilise code existant)
- üéØ **ROI**: **1.67** ‚≠ê **QUICK WIN**

**Pourquoi ce score**:
- **Plus-value = 5**: Utile pour debug tier lists, mais pas essentiel
- **Difficult√© = 3**: R√©utilise m√©thodes existantes d'Assistant

**Features**:
- Afficher avg_delta2, variance, coverage pour chaque champion
- Distribution metrics (min/max/mean/median) du pool
- Identifier outliers (champions avec donn√©es insuffisantes)
- Export vers CSV/JSON (optionnel)

**Int√©gration**: Pool Manager Menu

```
Pool Manager:
1. Create New Pool
2. Edit Existing Pool
3. Delete Pool
4. View Pool Statistics  ‚Üê NOUVEAU
5. Search Pools
6. Back
```

**Exemple affichage**:
```
=== Pool Statistics: TOP_SOLOQ_POOL ===

Champion Count: 43
Total Matchups: 1,547

Distribution:
- Avg Delta2: 0.85 (min: -2.1, max: 3.4)
- Variance: 1.24 (min: 0.3, max: 4.8)
- Coverage: 87% (min: 45%, max: 98%)

Top 5 Best Performers:
1. Aatrox     - Avg Delta2: 3.4
2. Camille    - Avg Delta2: 2.9
...

Champions with Low Data:
- Gwen        - Coverage: 45% (insufficient)
- K'Sante     - Coverage: 52% (borderline)
```

**B√©n√©fices**:
- ‚úÖ Debug tier lists facilement
- ‚úÖ Identifier champions √† re-scraper
- ‚úÖ Valider normalization ranges

---

### ‚≠ê T√¢che #11: Automatisation Mise √† Jour BD (Service Windows)
**Status**: ‚ùå Not started
**Effort**: 2-3 jours (16-24h)

**Scores Fibonacci**:
- üìà **Plus-value**: **13** (BD toujours √† jour automatiquement)
- üîß **Difficult√©**: **8** (complexe - service Windows silencieux + scraping parall√®le requis)
- üéØ **ROI**: **1.63** ‚≠ê‚≠ê **HAUTE VALEUR**

**Pourquoi ce score**:
- **Plus-value = 13**: BD √† jour sans intervention manuelle = gain temps massif + donn√©es fra√Æches
- **Difficult√© = 8**: Service Windows background + scraping parall√®le (T√¢che #4) + gestion ressources + processus silencieux non-bloquant

**‚ö†Ô∏è CRITICAL - D√âPENDANCE**: Cette t√¢che **REQUIERT T√¢che #4** (Web Scraping Parall√®le) ‚ö°
- **Sans parall√©lisation**: 30-60 min de parsing = **PC bloqu√© pendant 1h** ‚ùå INACCEPTABLE
- **Avec parall√©lisation**: 6-8 min = **Processus background acceptable** ‚úÖ
- **Recommandation**: Impl√©menter T√¢che #4 d'abord, puis T√¢che #11

**Probl√®me actuel**:
- ‚ùå Mise √† jour manuelle de la BD (parsing 30-60 min)
- ‚ùå Donn√©es potentiellement obsol√®tes entre patches
- ‚ùå Oublis de mise √† jour avant tournois

**Solutions propos√©es**:

#### Option 1: Windows Service + Task Scheduler (Recommand√© pour desktop)
**Complexit√©**: Moyenne | **Flexibilit√©**: Haute

**‚ö†Ô∏è IMPORTANT**: Simple Task Scheduler **N'EST PAS SUFFISANT** pour un processus silencieux.
- Task Scheduler = Ex√©cution en foreground (bloque le PC pendant parsing)
- Windows Service = Ex√©cution en background (ne bloque pas le PC)

**Solution recommand√©e**: Windows Service avec priorit√© BELOW_NORMAL + Task Scheduler pour trigger

```python
# scripts/auto_update_db.py
"""
Script automatis√© de mise √† jour BD.
S'ex√©cute en arri√®re-plan sans bloquer le PC.
REQUIERT: Web scraping parall√®le (T√¢che #4) pour temps d'ex√©cution < 10 min.
"""
import sys
import os
import psutil
from datetime import datetime
import json
from pathlib import Path

# Set process priority to BELOW_NORMAL to avoid blocking PC
try:
    p = psutil.Process(os.getpid())
    p.nice(psutil.BELOW_NORMAL_PRIORITY_CLASS)  # Windows: priorit√© basse
except:
    pass  # Fallback if psutil not available

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.db import Database
from src.parser import Parser
from src.config import config, get_resource_path
from src.constants import SOLOQ_POOL

def send_notification(title, message):
    """Send Windows notification."""
    try:
        from win10toast import ToastNotifier
        toaster = ToastNotifier()
        toaster.show_toast(title, message, duration=10, threaded=True)
    except:
        print(f"[NOTIFICATION] {title}: {message}")

def log_update(status, message):
    """Log update to file."""
    log_file = get_resource_path('logs/auto_update.log')
    os.makedirs(os.path.dirname(log_file), exist_ok=True)

    with open(log_file, 'a', encoding='utf-8') as f:
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        f.write(f"[{timestamp}] {status}: {message}\n")

def check_patch_version():
    """Check if patch version changed on LoLalytics."""
    # Scrape current patch from LoLalytics
    # Compare with last known patch
    # Return True if new patch detected
    pass

def main():
    try:
        log_update("START", "Auto-update BD started")
        send_notification("LeagueStats Coach", "Mise √† jour BD d√©marr√©e...")

        # 1. Check patch version
        new_patch = check_patch_version()
        if not new_patch:
            log_update("SKIP", "No new patch detected, skipping update")
            return

        # 2. Initialize DB and Parser
        db_path = get_resource_path('data/db.db')
        db = Database(db_path)
        db.connect()

        parser = Parser(db)

        # 3. Parse SOLOQ_POOL only (faster, ~5-10 min with parallel scraping)
        log_update("PROGRESS", f"Parsing {len(SOLOQ_POOL)} champions...")

        success_count = 0
        for i, champion in enumerate(SOLOQ_POOL):
            try:
                parser.parse_champion(champion, role='all')
                success_count += 1

                # Log progress every 10 champions
                if (i + 1) % 10 == 0:
                    log_update("PROGRESS", f"Parsed {i+1}/{len(SOLOQ_POOL)} champions")
            except Exception as e:
                log_update("ERROR", f"Failed to parse {champion}: {e}")

        # 4. Recalculate champion scores
        log_update("PROGRESS", "Recalculating champion scores...")
        # Call recalculate scores method

        db.close()

        # 5. Success notification
        log_update("SUCCESS", f"Update completed: {success_count}/{len(SOLOQ_POOL)} champions")
        send_notification(
            "LeagueStats Coach ‚úÖ",
            f"BD mise √† jour avec succ√®s!\n{success_count} champions pars√©s."
        )

    except Exception as e:
        log_update("FATAL", f"Update failed: {e}")
        send_notification(
            "LeagueStats Coach ‚ùå",
            f"√âchec mise √† jour BD: {str(e)}"
        )
        sys.exit(1)

if __name__ == '__main__':
    main()
```

**Configuration: Priorit√© Process + Task Scheduler**:

**√âtape 1: Script avec priorit√© basse** (d√©j√† fait dans le code ci-dessus)
```python
# Le script d√©finit automatiquement BELOW_NORMAL_PRIORITY_CLASS
# Cela permet au parsing de tourner en background sans ralentir le PC
```

**√âtape 2: Task Scheduler avec options avanc√©es**:
```powershell
# Cr√©er t√¢che planifi√©e qui s'ex√©cute tous les jours √† 3h AM
$action = New-ScheduledTaskAction -Execute "pythonw.exe" `  # pythonw = pas de console visible
                                  -Argument "C:\path\to\scripts\auto_update_db.py"
$trigger = New-ScheduledTaskTrigger -Daily -At 3am
$settings = New-ScheduledTaskSettingsSet `
    -StartWhenAvailable `
    -RunOnlyIfNetworkAvailable `
    -DontStopOnIdleEnd `
    -AllowStartIfOnBatteries `
    -Priority 7  # Priorit√© basse (0=haute, 10=basse)

Register-ScheduledTask -TaskName "LeagueStats Auto-Update" `
                       -Action $action `
                       -Trigger $trigger `
                       -Settings $settings `
                       -Description "Mise √† jour automatique BD LeagueStats (background)"
```

**√âtape 3: Alternative - Windows Service (optionnel, plus complexe)**:
```python
# Pour transformer en vrai Windows Service (non-recommand√© sauf besoin sp√©cifique)
# Utiliser pywin32 ou NSSM (Non-Sucking Service Manager)
# NSSM est plus simple:
# nssm install LeagueStatsUpdater "C:\Python313\pythonw.exe" "C:\path\to\auto_update_db.py"
# nssm set LeagueStatsUpdater AppPriority BELOW_NORMAL_PRIORITY_CLASS
```

**Avantages**:
- ‚úÖ Natif Windows, pas de serveur n√©cessaire
- ‚úÖ Ex√©cution locale, pas de co√ªts cloud
- ‚úÖ Notifications desktop
- ‚úÖ **Processus background silencieux** (avec pythonw + priorit√© basse)
- ‚úÖ **Ne bloque PAS le PC** (si T√¢che #4 impl√©ment√©e: 6-8 min seulement)

**Inconv√©nients**:
- ‚ùå N√©cessite PC allum√© √† l'heure planifi√©e
- ‚ùå Pas accessible √† distance
- ‚ö†Ô∏è **REQUIERT T√¢che #4** (sans parall√©lisation: 1h de parsing = bloquant)

---

#### Option 2: Serveur Cloud avec Cron (Pour d√©ploiement permanent)
**Complexit√©**: Moyenne | **Flexibilit√©**: √âlev√©e

**Architecture**:
```
VPS Cloud (AWS/DigitalOcean/OVH)
‚îú‚îÄ‚îÄ Ubuntu Server 22.04
‚îú‚îÄ‚îÄ Python 3.13 + dependencies
‚îú‚îÄ‚îÄ LeagueStats app
‚îú‚îÄ‚îÄ Cron job (quotidien √† 3h AM UTC)
‚îî‚îÄ‚îÄ Base de donn√©es SQLite accessible via SFTP/API
```

**Cron Configuration**:
```bash
# /etc/cron.d/leaguestats-update
# Ex√©cute mise √† jour tous les jours √† 3h AM
0 3 * * * leaguestats /usr/bin/python3 /opt/leaguestats/scripts/auto_update_db.py >> /var/log/leaguestats/update.log 2>&1
```

**Script avec notifications email**:
```python
# scripts/auto_update_db_server.py
import smtplib
from email.mime.text import MIMEText

def send_email_notification(subject, body):
    """Send email notification via SMTP."""
    msg = MIMEText(body)
    msg['Subject'] = subject
    msg['From'] = 'leaguestats@yourdomain.com'
    msg['To'] = 'your-email@gmail.com'

    with smtplib.SMTP('smtp.gmail.com', 587) as server:
        server.starttls()
        server.login('your-email@gmail.com', 'app-password')
        server.send_message(msg)

# Reste du code similaire √† Option 1
```

**Synchronisation BD**:
```bash
# Sur ta machine locale, t√©l√©charger BD mise √† jour
rsync -avz user@your-server:/opt/leaguestats/data/db.db ./data/db.db

# Ou via script Python
import paramiko

def download_updated_db():
    """Download updated DB from server via SFTP."""
    ssh = paramiko.SSHClient()
    ssh.load_system_host_keys()
    ssh.connect('your-server.com', username='user', key_filename='~/.ssh/id_rsa')

    sftp = ssh.open_sftp()
    sftp.get('/opt/leaguestats/data/db.db', './data/db.db')
    sftp.close()
    ssh.close()
```

**Co√ªt**: ~5-10‚Ç¨/mois (VPS DigitalOcean Droplet 1GB RAM)

**Avantages**:
- ‚úÖ Toujours actif, pas besoin PC allum√©
- ‚úÖ Accessible √† distance (SFTP/API)
- ‚úÖ Notifications email/SMS
- ‚úÖ Logs centralis√©s

**Inconv√©nients**:
- ‚ùå Co√ªt mensuel r√©current
- ‚ùå Configuration serveur requise

---

#### Option 3: GitHub Actions (Gratuit, Cloud)
**Complexit√©**: Faible | **Flexibilit√©**: Moyenne

**Workflow GitHub Actions**:
```yaml
# .github/workflows/auto-update-db.yml
name: Auto-Update Database

on:
  schedule:
    # Ex√©cute tous les jours √† 3h AM UTC
    - cron: '0 3 * * *'
  workflow_dispatch:  # Permet ex√©cution manuelle

jobs:
  update-database:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.13'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          sudo apt-get install -y firefox-geckodriver

      - name: Run auto-update script
        run: python scripts/auto_update_db.py
        env:
          NOTIFICATION_EMAIL: ${{ secrets.NOTIFICATION_EMAIL }}

      - name: Upload updated database
        uses: actions/upload-artifact@v3
        with:
          name: database-${{ github.run_number }}
          path: data/db.db

      - name: Commit and push if changed
        run: |
          git config user.name "GitHub Actions Bot"
          git config user.email "actions@github.com"
          git add data/db.db
          git diff --quiet && git diff --staged --quiet || \
            (git commit -m "Auto-update: Database updated $(date)" && git push)
```

**R√©cup√©ration BD**:
```bash
# Pull latest changes
git pull origin main

# Ou t√©l√©charger artifact depuis GitHub Actions UI
```

**Avantages**:
- ‚úÖ **100% gratuit** pour repos publics
- ‚úÖ Aucun serveur √† maintenir
- ‚úÖ Logs dans GitHub Actions
- ‚úÖ Historique Git des mises √† jour

**Inconv√©nients**:
- ‚ùå Limite 2000 min/mois (gratuit)
- ‚ùå Ex√©cution plus lente (cold start)
- ‚ùå DB stock√©e dans Git (limite taille repo)

---

**Recommandation**:

| Cas d'usage | Solution recommand√©e | Raison |
|-------------|---------------------|--------|
| Usage personnel desktop | **Option 1: Task Scheduler + Background** | Simple, gratuit, local, silencieux |
| Team/Gaming House | **Option 2: VPS Cloud** | Toujours √† jour, accessible tous |
| Open Source / Communaut√© | **Option 3: GitHub Actions** | Gratuit, transparent, versionn√© |

**Impl√©mentation sugg√©r√©e (Mix)**:
1. **REQUIS d'abord**: T√¢che #4 (Web Scraping Parall√®le) - 1-2 jours ‚ö°
2. **Court terme**: Option 1 (Task Scheduler + Background) - 2-3 jours
3. **Moyen terme**: Option 3 (GitHub Actions) - 0.5 jour (optionnel)
4. **Long terme**: Option 2 (VPS) si n√©cessaire - 1 jour (optionnel)

**‚ö†Ô∏è ORDRE OBLIGATOIRE**:
1. Impl√©menter T√¢che #4 (parsing 30-60min ‚Üí 6-8min)
2. Puis impl√©menter T√¢che #11 (auto-update background)
3. Sinon: T√¢che #11 bloquera le PC pendant 1h chaque jour ‚ùå

**B√©n√©fices**:
- ‚úÖ BD toujours √† jour avec dernier patch
- ‚úÖ Z√©ro intervention manuelle
- ‚úÖ Notifications en cas d'√©chec
- ‚úÖ Logs pour debugging
- ‚úÖ Gain temps massif (30-60 min/semaine √©conomis√©s)

---

## üü¢ PRIORIT√â BASSE - Sprint 3+ (1-2 mois)

### T√¢che #10: CI/CD Pipeline
**Status**: ‚ùå Not started
**Effort**: 1 jour (8h)

**Scores Fibonacci**:
- üìà **Plus-value**: **8** (automatisation, qualit√©)
- üîß **Difficult√©**: **5** (mod√©r√© - config YAML)
- üéØ **ROI**: **1.60** ‚≠ê **BONNE VALEUR**

**Pourquoi ce score**:
- **Plus-value = 8**: Tests auto, builds auto, d√©tection bugs early
- **Difficult√© = 5**: Config GitHub Actions + debugging pipeline

**Plateforme**: GitHub Actions

**Pipeline propos√©**:
```yaml
# .github/workflows/ci.yml
name: LeagueStats Coach CI/CD

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: windows-latest
    steps:
      - uses: actions/checkout@v3

      - name: Setup Python 3.13
        uses: actions/setup-python@v4
        with:
          python-version: '3.13'

      - name: Install dependencies
        run: |
          pip install -r requirements-dev.txt

      - name: Run linting
        run: |
          pylint src/ --fail-under=8.0

      - name: Run tests
        run: |
          pytest tests/ --cov=src --cov-report=xml --cov-report=term

      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage.xml

  build:
    runs-on: windows-latest
    needs: test
    if: github.ref == 'refs/heads/main'
    steps:
      - uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.13'

      - name: Build executable
        run: |
          pip install -r requirements-dev.txt
          python build_app.py

      - name: Create package
        run: python create_package.py

      - name: Upload artifact
        uses: actions/upload-artifact@v3
        with:
          name: LeagueStatsCoach-${{ github.sha }}
          path: LeagueStatsCoach_Portable.zip
```

**B√©n√©fices**:
- ‚úÖ Tests automatiques √† chaque commit
- ‚úÖ Build automatique sur main
- ‚úÖ D√©tection r√©gressions imm√©diate
- ‚úÖ Artefacts versionn√©s

---

### T√¢che #9: Syst√®me de Migrations de Base de Donn√©es
**Status**: ‚ùå Not started
**Effort**: 1 jour (8h)

**Scores Fibonacci**:
- üìà **Plus-value**: **8** ‚¨ÜÔ∏è (infrastructure BD critique - √©vite pertes donn√©es)
- üîß **Difficult√©**: **5** (mod√©r√© - config Alembic)
- üéØ **ROI**: **1.60** (dette technique infrastructure)

**Pourquoi ce score** (r√©vis√© pour Dette Technique First):
- **Plus-value = 8** (anciennement 5):
  - ‚úÖ **Protection donn√©es**: √âvite DROP TABLE = z√©ro perte de donn√©es utilisateur
  - ‚úÖ **Infrastructure critique**: Base donn√©es = fondation app, doit √™tre fiable
  - ‚úÖ **√âvolutivit√©**: Permet changements sch√©ma sans migration manuelle douloureuse
  - ‚úÖ **Professionnalisme**: Migrations = standard industrie, pratique obligatoire production
  - üìä **Raisonnement**: Impl√©menter migrations MAINTENANT √©vite perte donn√©es catastrophique PLUS TARD
- **Difficult√© = 5**: Config Alembic + √©criture migrations initiales

**Probl√®me actuel**: `DROP TABLE` perd toutes les donn√©es.

**Solution**: Utiliser **Alembic**

```bash
# Installation
pip install alembic

# Initialisation
alembic init migrations

# Cr√©er migration
alembic revision --autogenerate -m "Add role column to champions"

# Appliquer
alembic upgrade head

# Rollback
alembic downgrade -1
```

**Exemple migration**:
```python
# migrations/versions/001_add_role_column.py
def upgrade():
    op.add_column('champions', sa.Column('role', sa.String(20)))

def downgrade():
    op.drop_column('champions', 'role')
```

**B√©n√©fices**:
- ‚úÖ Migrations r√©versibles
- ‚úÖ Historique changements sch√©ma
- ‚úÖ Pas de perte de donn√©es

---

### T√¢che #6: Interface Graphique (GUI)
**Status**: ‚ùå Not started
**Effort**: 1-2 semaines (40-80h)

**Scores Fibonacci**:
- üìà **Plus-value**: **13** (UX massif, accessibilit√©)
- üîß **Difficult√©**: **21** (tr√®s complexe - nouveau paradigme)
- üéØ **ROI**: **0.62** (faible ROI, gros effort)

**Pourquoi ce score**:
- **Plus-value = 13**: Am√©lioration UX massive, attire users non-tech
- **Difficult√© = 21**: Nouveau paradigme UI, event-driven, layout complexe

**Options**:
- **Option 1**: `tkinter` (l√©ger, inclus Python, courbe apprentissage faible)
- **Option 2**: `PyQt6` (moderne, professionnel, mais complexe)
- **Option 3**: Web UI (`Flask` + React/Vue, accessible depuis navigateur)

**Recommandation**: Commencer avec **tkinter** pour prototype rapide.

**Exemple prototype tkinter**:
```python
import tkinter as tk
from tkinter import ttk

class LeagueStatsGUI:
    def __init__(self):
        self.root = tk.Tk()
        self.root.title("LeagueStats Coach")
        self.root.geometry("800x600")

        # Menu bar
        menubar = tk.Menu(self.root)
        self.root.config(menu=menubar)

        # Draft Coach Tab
        draft_frame = ttk.Frame(self.root)
        draft_frame.pack(fill='both', expand=True)

        # Role selection
        ttk.Label(draft_frame, text="Select Role:").pack()
        role_var = tk.StringVar()
        roles = ['Top', 'Jungle', 'Mid', 'ADC', 'Support']
        ttk.Combobox(draft_frame, textvariable=role_var, values=roles).pack()

        # Recommendations display
        rec_text = tk.Text(draft_frame, height=20)
        rec_text.pack()

    def run(self):
        self.root.mainloop()

if __name__ == '__main__':
    app = LeagueStatsGUI()
    app.run()
```

**‚ö†Ô∏è Note**: Gros investissement, √† faire **apr√®s** stabilisation du backend.

---

### T√¢che #7: Support Multi-Plateformes
**Status**: ‚ùå Not started
**Effort**: 2-3 jours (16-24h)

**Scores Fibonacci**:
- üìà **Plus-value**: **5** (portabilit√©, mais users Windows majoritaires)
- üîß **Difficult√©**: **8** (mod√©r√© - tests sur chaque OS)
- üéØ **ROI**: **0.63**

**Pourquoi ce score**:
- **Plus-value = 5**: Users LoL majoritairement Windows, Linux/Mac minoritaires
- **Difficult√© = 8**: Tests sur 3 OS, paths diff√©rents, PyInstaller configs

**Cibles**: Linux, macOS

**D√©fis**:
- D√©tection de navigateur multi-plateformes
- Paths diff√©rents (Windows `C:\` vs Unix `/home`)
- PyInstaller configs par OS
- Tests sur chaque plateforme

**Exemple code multi-plateforme**:
```python
import platform
import os

def get_browser_path():
    """Get browser executable path for current OS."""
    system = platform.system()

    if system == 'Windows':
        return r'C:\Program Files\Mozilla Firefox\firefox.exe'
    elif system == 'Darwin':  # macOS
        return '/Applications/Firefox.app/Contents/MacOS/firefox'
    elif system == 'Linux':
        return '/usr/bin/firefox'
    else:
        raise OSError(f"Unsupported OS: {system}")
```

---

### T√¢che #8: Internationalisation (i18n)
**Status**: ‚ùå Not started
**Effort**: 1-2 jours (8-16h)

**Scores Fibonacci**:
- üìà **Plus-value**: **3** (accessibilit√©, mais users FR/EN d√©j√† couverts)
- üîß **Difficult√©**: **5** (mod√©r√© - extraction strings)
- üéØ **ROI**: **0.60**

**Pourquoi ce score**:
- **Plus-value = 3**: Nice to have, mais pas critique (code d√©j√† en FR/EN mixte)
- **Difficult√© = 5**: Extraction toutes les strings, gestion fichiers .po

**Langues cibles**: Fran√ßais, Anglais

**M√©thode**: Utiliser `gettext`

```python
import gettext

# Setup
locale_dir = 'locales'
lang = 'fr'  # ou 'en'
translation = gettext.translation('app', locale_dir, languages=[lang])
translation.install()
_ = translation.gettext

# Usage dans le code
print(_("Welcome to LeagueStats Coach"))
print(_("Select your role:"))
```

**Structure fichiers**:
```
locales/
‚îú‚îÄ‚îÄ fr/
‚îÇ   ‚îî‚îÄ‚îÄ LC_MESSAGES/
‚îÇ       ‚îú‚îÄ‚îÄ app.po   # Fichier source (√©ditable)
‚îÇ       ‚îî‚îÄ‚îÄ app.mo   # Fichier compil√©
‚îî‚îÄ‚îÄ en/
    ‚îî‚îÄ‚îÄ LC_MESSAGES/
        ‚îú‚îÄ‚îÄ app.po
        ‚îî‚îÄ‚îÄ app.mo
```

**Commandes**:
```bash
# Extraire strings
xgettext -o locales/app.pot src/*.py

# Compiler .po ‚Üí .mo
msgfmt locales/fr/LC_MESSAGES/app.po -o locales/fr/LC_MESSAGES/app.mo
```

---

### T√¢che #12: Architecture Client-Serveur + Web App
**Status**: ‚ùå Not started
**Effort**: 2-3 semaines (80-120h)

**Scores Fibonacci**:
- üìà **Plus-value**: **21** (r√©volution UX + BD centralis√©e)
- üîß **Difficult√©**: **34** (tr√®s complexe - full-stack + d√©ploiement)
- üéØ **ROI**: **0.62** (gros investissement, gains √† long terme)

**Pourquoi ce score**:
- **Plus-value = 21**: Acc√®s distant BD, multi-users, web UI moderne, toujours √† jour
- **Difficult√© = 34**: Backend API + Frontend React + Base donn√©es PostgreSQL + D√©ploiement cloud + Auth

**Vision**: Transformer LeagueStats en **SaaS accessible depuis navigateur**

---

#### Architecture Propos√©e

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    UTILISATEURS                          ‚îÇ
‚îÇ  Desktop PC ‚îÇ Laptop ‚îÇ Tablette ‚îÇ Smartphone             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ HTTPS
                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              WEB APP (React/Vue/Svelte)                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Draft Coach  ‚îÇ Tier Lists   ‚îÇ Champion Pools       ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Real-time UI ‚îÇ Visualisation‚îÇ Gestion Pools        ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ REST API / GraphQL / WebSocket
                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           BACKEND API (FastAPI / Flask)                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Auth JWT     ‚îÇ API Endpoints‚îÇ WebSocket Server     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Rate Limiting‚îÇ Caching Redis‚îÇ Background Tasks     ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ          Core Logic (Python)                      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Assistant (algorithmes scoring)                ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Parser (web scraping)                          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Pool Manager                                   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - LCU Client (pour draft real-time)             ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ SQL / ORM (SQLAlchemy)
                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      BASE DE DONN√âES (PostgreSQL / MySQL)                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ champions    ‚îÇ matchups     ‚îÇ users                ‚îÇ ‚îÇ
‚îÇ  ‚îÇ pools        ‚îÇ drafts       ‚îÇ subscriptions        ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

#### Stack Technologique Recommand√©e

**Backend**:
- **Framework**: FastAPI (moderne, async, auto-docs)
- **ORM**: SQLAlchemy (migration depuis SQLite facile)
- **Database**: PostgreSQL 15+ (production) / SQLite (dev)
- **Cache**: Redis (optionnel, pour tier lists)
- **Auth**: JWT avec refresh tokens
- **Background Jobs**: Celery + Redis (parsing automatique)
- **WebSocket**: FastAPI WebSocket (draft real-time)

**Frontend**:
- **Framework**: React 18 + TypeScript
  - Alternative: Vue 3 / Svelte (plus simple)
- **UI Library**: shadcn/ui ou Material-UI
- **State Management**: Zustand / Redux Toolkit
- **API Client**: React Query (caching auto)
- **WebSocket**: Socket.io-client
- **Build**: Vite (rapide)

**Infrastructure**:
- **Hosting Backend**: Railway / Render / DigitalOcean App Platform
- **Hosting Frontend**: Vercel / Netlify (gratuit!)
- **Database**: Railway PostgreSQL / Supabase (gratuit tier)
- **CDN**: Cloudflare (gratuit)
- **Monitoring**: Sentry (erreurs) + Plausible (analytics)

**Co√ªt estim√©**: 0-15‚Ç¨/mois (gratuit avec tiers gratuits)

---

#### √âtapes d'Impl√©mentation

**Phase 1: Backend API (1 semaine)**

```python
# backend/main.py - FastAPI setup
from fastapi import FastAPI, Depends, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from sqlalchemy.orm import Session
import uvicorn

app = FastAPI(title="LeagueStats API", version="2.0")

# CORS pour acc√®s depuis web app
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "https://leaguestats.app"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Routes API
@app.get("/api/v1/champions")
async def get_champions(db: Session = Depends(get_db)):
    """Get all champions."""
    champions = db.query(Champion).all()
    return {"champions": [ChampionSchema.from_orm(c) for c in champions]}

@app.get("/api/v1/champions/{champion_id}/matchups")
async def get_champion_matchups(champion_id: int, db: Session = Depends(get_db)):
    """Get matchups for a champion."""
    matchups = db.query(Matchup).filter(Matchup.champion_id == champion_id).all()
    return {"matchups": [MatchupSchema.from_orm(m) for m in matchups]}

@app.post("/api/v1/pools")
async def create_pool(
    pool: PoolCreate,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """Create a new champion pool."""
    new_pool = Pool(**pool.dict(), user_id=current_user.id)
    db.add(new_pool)
    db.commit()
    return {"pool": PoolSchema.from_orm(new_pool)}

@app.get("/api/v1/tierlist/{role}")
async def get_tierlist(role: str, pool_id: Optional[int] = None):
    """Generate tier list for role."""
    assistant = Assistant()
    tierlist = assistant.generate_tierlist(role, pool_id)
    return {"tierlist": tierlist}

# WebSocket pour draft real-time
@app.websocket("/ws/draft/{draft_id}")
async def draft_websocket(websocket: WebSocket, draft_id: str):
    await websocket.accept()
    # Stream draft updates en temps r√©el
    draft_monitor = DraftMonitor()
    async for update in draft_monitor.stream_updates():
        await websocket.send_json(update)

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

**Endpoints API** (exemples):
```
GET    /api/v1/champions                  # Liste champions
GET    /api/v1/champions/{id}/matchups    # Matchups champion
POST   /api/v1/pools                      # Cr√©er pool
GET    /api/v1/pools/{id}                 # D√©tails pool
GET    /api/v1/tierlist/{role}            # Tier list
POST   /api/v1/auth/register              # Inscription
POST   /api/v1/auth/login                 # Connexion
WS     /ws/draft/{id}                     # Draft real-time
```

---

**Phase 2: Migration Base de Donn√©es (2-3 jours)**

```python
# backend/models.py - SQLAlchemy models
from sqlalchemy import Column, Integer, String, Float, ForeignKey, DateTime
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import relationship

Base = declarative_base()

class Champion(Base):
    __tablename__ = "champions"

    id = Column(Integer, primary_key=True)
    key = Column(String(50), unique=True)  # "Aatrox"
    name = Column(String(100))
    title = Column(String(200))
    matchups = relationship("Matchup", back_populates="champion")

class Matchup(Base):
    __tablename__ = "matchups"

    id = Column(Integer, primary_key=True)
    champion_id = Column(Integer, ForeignKey("champions.id"))
    enemy_id = Column(Integer, ForeignKey("champions.id"))
    winrate = Column(Float)
    delta1 = Column(Float)
    delta2 = Column(Float)
    pickrate = Column(Float)
    games = Column(Integer)

    champion = relationship("Champion", foreign_keys=[champion_id])
    enemy = relationship("Champion", foreign_keys=[enemy_id])

class User(Base):
    __tablename__ = "users"

    id = Column(Integer, primary_key=True)
    email = Column(String(255), unique=True)
    password_hash = Column(String(255))
    created_at = Column(DateTime)
    pools = relationship("Pool", back_populates="user")

class Pool(Base):
    __tablename__ = "pools"

    id = Column(Integer, primary_key=True)
    user_id = Column(Integer, ForeignKey("users.id"))
    name = Column(String(100))
    description = Column(String(500))
    champions = Column(JSON)  # Liste IDs champions

    user = relationship("User", back_populates="pools")
```

**Migration SQLite ‚Üí PostgreSQL**:
```bash
# Export SQLite
sqlite3 data/db.db .dump > dump.sql

# Import PostgreSQL
psql -U postgres -d leaguestats < dump.sql

# Ou via script Python
import sqlite3
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

# Read from SQLite
sqlite_conn = sqlite3.connect('data/db.db')
sqlite_cursor = sqlite_conn.cursor()
sqlite_cursor.execute("SELECT * FROM champions")
champions = sqlite_cursor.fetchall()

# Write to PostgreSQL
pg_engine = create_engine('postgresql://user:pass@localhost/leaguestats')
Session = sessionmaker(bind=pg_engine)
session = Session()

for champ in champions:
    new_champ = Champion(id=champ[0], name=champ[1], ...)
    session.add(new_champ)

session.commit()
```

---

**Phase 3: Frontend React (1 semaine)**

```typescript
// frontend/src/App.tsx - React app structure
import { BrowserRouter, Routes, Route } from 'react-router-dom'
import { QueryClient, QueryClientProvider } from 'react-query'
import { DraftCoach } from './pages/DraftCoach'
import { TierLists } from './pages/TierLists'
import { PoolManager } from './pages/PoolManager'
import { Login } from './pages/Login'

const queryClient = new QueryClient()

function App() {
  return (
    <QueryClientProvider client={queryClient}>
      <BrowserRouter>
        <Routes>
          <Route path="/" element={<DraftCoach />} />
          <Route path="/tierlists" element={<TierLists />} />
          <Route path="/pools" element={<PoolManager />} />
          <Route path="/login" element={<Login />} />
        </Routes>
      </BrowserRouter>
    </QueryClientProvider>
  )
}

// frontend/src/components/TierListDisplay.tsx
import { useQuery } from 'react-query'
import { fetchTierList } from '../api/client'

export function TierListDisplay({ role }: { role: string }) {
  const { data, isLoading } = useQuery(['tierlist', role], () =>
    fetchTierList(role)
  )

  if (isLoading) return <div>Loading tier list...</div>

  return (
    <div className="tier-list">
      {['S', 'A', 'B', 'C'].map(tier => (
        <div key={tier} className="tier-row">
          <h3>{tier} Tier</h3>
          <div className="champions">
            {data.tierlist[tier].map(champ => (
              <ChampionCard key={champ.id} champion={champ} />
            ))}
          </div>
        </div>
      ))}
    </div>
  )
}

// frontend/src/hooks/useDraftWebSocket.ts
import { useEffect, useState } from 'react'

export function useDraftWebSocket(draftId: string) {
  const [recommendations, setRecommendations] = useState([])

  useEffect(() => {
    const ws = new WebSocket(`ws://localhost:8000/ws/draft/${draftId}`)

    ws.onmessage = (event) => {
      const update = JSON.parse(event.data)
      setRecommendations(update.recommendations)
    }

    return () => ws.close()
  }, [draftId])

  return recommendations
}
```

---

**Phase 4: D√©ploiement (2-3 jours)**

**Option 1: Railway (Recommand√© - Simple)**
```bash
# Deploy backend + PostgreSQL en 1 clic
railway login
railway init
railway up

# Variables d'environnement auto-configur√©es
DATABASE_URL=postgresql://...
REDIS_URL=redis://...
```

**Option 2: DigitalOcean App Platform**
```yaml
# app.yaml
name: leaguestats
services:
  - name: api
    github:
      repo: username/leaguestats
      branch: main
    build_command: pip install -r requirements.txt
    run_command: uvicorn main:app --host 0.0.0.0 --port 8000
    envs:
      - key: DATABASE_URL
        scope: RUN_AND_BUILD_TIME
        value: ${db.DATABASE_URL}

databases:
  - name: db
    engine: PG
    version: "15"
```

**Frontend d√©ploy√© sur Vercel**:
```bash
cd frontend
vercel --prod
# Auto-deploy √† chaque push sur main
```

---

#### Features Cl√©s Web App

1. **Draft Coach Real-Time**
   - WebSocket connection vers LCU
   - Affichage top 3 recommandations live
   - Historique drafts sauvegard√©s
   - Partage draft via URL

2. **Tier Lists Interactives**
   - Filtrage par r√¥le
   - Tri par m√©trique (winrate, delta2, etc.)
   - Comparaison multiple pools
   - Export PNG/PDF

3. **Pool Manager Cloud**
   - Sync automatique entre devices
   - Partage pools avec √©quipe
   - Import/Export JSON
   - Tags et cat√©gories

4. **Dashboard Analytics**
   - Statistiques d'utilisation
   - Champions populaires
   - Trends patch par patch
   - Suggestions personnalis√©es

5. **Authentification & Comptes**
   - Inscription/Connexion
   - Profils utilisateurs
   - Favoris et historique
   - Plans gratuit/premium (optionnel)

---

#### Avantages Architecture Client-Serveur

‚úÖ **Utilisateur**:
- Acc√®s depuis n'importe quel device
- Pas d'installation requise
- BD toujours √† jour (serveur scrape auto)
- Synchronisation multi-devices
- Interface moderne et r√©active

‚úÖ **D√©veloppement**:
- Backend Python r√©utilis√© (Assistant, Parser)
- API testable facilement
- Scalabilit√© (Redis cache, load balancing)
- Monitoring et analytics int√©gr√©s
- CI/CD simple (auto-deploy)

‚úÖ **Business** (si monetization future):
- Mod√®le SaaS (abonnements)
- Freemium (tier gratuit + premium)
- Analytics utilisateurs
- A/B testing facile

---

#### Inconv√©nients & D√©fis

‚ùå **Complexit√©**:
- Full-stack d√©veloppement
- DevOps et d√©ploiement
- S√©curit√© (auth, CORS, rate limiting)
- Co√ªts cloud r√©currents (m√™me minimes)

‚ùå **Maintenance**:
- Serveur √† surveiller 24/7
- Backups BD r√©guliers
- Gestion utilisateurs
- Support utilisateurs potentiels

---

#### Timeline & Roadmap

**MVP (4 semaines)**:
- Semaine 1: Backend API (FastAPI) + Migration BD
- Semaine 2: Frontend React (pages principales)
- Semaine 3: Features core (Draft, Tier Lists, Pools)
- Semaine 4: D√©ploiement + Tests

**Version 1.0 (2 mois)**:
- MVP + Auth utilisateurs
- WebSocket draft real-time
- Am√©lioration UI/UX
- Tests et optimisations

**Version 2.0 (3-4 mois)**:
- Dashboard analytics
- Partage social
- Mobile responsive
- Premium features (optionnel)

---

#### ROI & D√©cision

**Investissement**: 80-120h (2-3 semaines full-time)

**Retour**:
- **Court terme**: Application moderne accessible partout
- **Moyen terme**: Base utilisateurs potentielle √©largie
- **Long terme**: Mon√©tisation possible (SaaS)

**Recommandation**:
- **Si usage perso/petit groupe**: Pas n√©cessaire (desktop app suffit)
- **Si ambition communaut√©/open-source**: Excellente id√©e
- **Si Gaming House/√©quipe pro**: Tr√®s utile (acc√®s centralis√©)

---

**D√©pendances requises**:
- T√¢che #4 (Web Scraping parall√®le) - Parsing auto serveur
- T√¢che #3 (Tests) - API test√©e avant production
- T√¢che #10 (CI/CD) - D√©ploiement automatis√©

**B√©n√©fices**:
- ‚úÖ Acc√®s BD distant depuis navigateur
- ‚úÖ Multi-users avec authentification
- ‚úÖ BD centralis√©e toujours √† jour
- ‚úÖ Interface moderne et r√©active
- ‚úÖ Scalable et maintenable
- ‚úÖ Potentiel mon√©tisation future

---

## üìä Matrice de D√©cision

### Quick Wins (ROI √©lev√©) üéØ

| T√¢che | Plus-value | Difficult√© | ROI | Temps | Statut |
|-------|------------|------------|-----|-------|--------|
| #2 Extraction hardcoded | 8 | 3 | **2.67** | 1 jour | ‚úÖ **FAIT** |
| #5 Pool Statistics | 5 | 3 | **1.67** | 1 jour | ‚ùå |
| #11 Auto-Update BD (Service) | 13 | 8 | **1.63** | 2-3 jours | ‚ùå ‚ö†Ô∏è |
| #4 Web Scraping parall√®le | 13 | 8 | **1.63** | 1-2 jours | ‚ùå |
| #9 Migrations BD | 8 ‚¨ÜÔ∏è | 5 | **1.60** | 1 jour | ‚ùå |
| #10 CI/CD | 8 | 5 | **1.60** | 1 jour | ‚ùå |

**‚ö†Ô∏è IMPORTANT**: T√¢che #11 **D√âPEND** de T√¢che #4 (faire #4 d'abord!)
**Total Quick Wins**: 5-8 jours restants pour gains massifs üöÄ (1 jour compl√©t√©)

---

### Dette Technique (Approche "Dette Technique First") üî¥üî¥üî¥

**Philosophie**: Investir dans la qualit√© MAINTENANT pour √©viter refactoring complexe PLUS TARD

| T√¢che | Plus-value | Difficult√© | ROI | Temps | Priorit√© |
|-------|------------|------------|-----|-------|----------|
| #1 Refactoring fichiers | 13 ‚¨ÜÔ∏è | 13 | **1.00** | 2-3 jours | üî¥üî¥üî¥ **NEXT** |
| #3 Tests Automatis√©s | 13 | 13 | **1.00** | 3-5 jours | üî¥üî¥ |
| #9 Migrations BD | 8 ‚¨ÜÔ∏è | 5 | **1.60** | 1 jour | üî¥ |

**Approche recommand√©e**: Dette Technique ‚Üí Refactoring + Tests + Migrations **AVANT** features
**Total**: 6-9 jours pour fondations solides et maintenabilit√© long terme
**Impact**: Base saine = v√©locit√© √©lev√©e pour TOUTES futures t√¢ches

---

### Gros Chantiers (Faire apr√®s stabilisation)

| T√¢che | Plus-value | Difficult√© | ROI | Temps |
|-------|------------|------------|-----|-------|
| #7 Multi-plateformes | 5 | 8 | 0.63 | 2-3 jours |
| #6 GUI Desktop | 13 | 21 | 0.62 | 1-2 semaines |
| #12 Web App (Client-Serveur) | 21 | 34 | 0.62 | 2-3 semaines |
| #8 i18n | 3 | 5 | 0.60 | 1-2 jours |

**Total**: 3-5 semaines - √Ä faire en Phase 3+ (apr√®s Dette Technique r√©solue)

---

## üéØ Sprint Planning Recommand√© (Dette Technique First)

### ‚úÖ Sprint 0 (COMPL√âT√â): Configuration Foundation
**Objectif**: Bases configurables et maintenables

- [x] #2 Extraction hardcoded values (1j) - ROI 2.67 ‚úÖ **FAIT**
- [x] Bug #2 fix (parser.py SyntaxWarning) (0.1j) ‚úÖ **FAIT**

**Total**: 1 jour ‚úÖ
**R√©sultat**: Code configurable, type-safe, IDE-documented, backward compatible

---

### üî¥ Sprint 1 (Semaine 1-2): Dette Technique First
**Objectif**: Fondations solides avant features
**Philosophie**: Refactoring + Infrastructure + Tests MAINTENANT = V√©locit√© √©lev√©e APR√àS

- [ ] #1 Refactoring fichiers monolithiques (2-3j) - ROI 1.00 üî¥üî¥üî¥ **NEXT**
  - D√©couper `lol_coach.py` (2,160 lignes) ‚Üí `src/ui/` modules
  - D√©couper `assistant.py` (2,381 lignes) ‚Üí `src/analysis/` modules
  - Objectif: <500 lignes/fichier
- [ ] #9 Migrations Base de Donn√©es (1j) - ROI 1.60 üî¥
  - Setup Alembic
  - Migrations initiales
  - Protection contre perte donn√©es
- [ ] #3 Framework Tests Automatis√©s (3-5j) - ROI 1.00 üî¥üî¥
  - Setup pytest + pytest-cov
  - Tests scoring algorithms (assistant.py)
  - Tests tier list generation
  - Objectif: 70% couverture

**Total**: 6-9 jours
**R√©sultat**: Code maintenable (<500 lignes/fichier), tests automatiques (70%+), migrations s√ªres
**Impact multiplicateur**: Toutes futures t√¢ches seront PLUS RAPIDES et PLUS S√õRES gr√¢ce √† ces fondations

---

### üü° Sprint 2 (Semaine 3-4): Performance & Features
**Objectif**: Gains utilisateur rapides (apr√®s fondations solides)

- [ ] #4 Web Scraping parall√®le (1-2j) - ROI 1.63 ‚ö°
  - ThreadPoolExecutor pour parall√©lisation
  - Retry logic avec exponential backoff
  - Parsing 30-60 min ‚Üí 6-8 min (80% am√©lioration)
- [ ] #11 Auto-Update BD (Service Windows) (2-3j) - ROI 1.63 ‚ö†Ô∏è **D√âPEND de #4**
  - Windows Service avec priorit√© BELOW_NORMAL
  - Processus background silencieux
  - Notifications Windows Toast
- [ ] #5 Pool Statistics Viewer (1j) - ROI 1.67
  - Affichage stats d√©taill√©es pools
  - Export CSV/JSON
- [ ] #10 CI/CD Pipeline (1j) - ROI 1.60
  - GitHub Actions
  - Tests automatiques
  - Build automatique

**Total**: 5-8 jours
**‚ö†Ô∏è Ordre critique**: T√¢che #4 **AVANT** T√¢che #11 (d√©pendance stricte)
**R√©sultat**: Parsing 80% plus rapide, BD auto-update silencieux, stats utiles, CI/CD fonctionnel

---

### üü¢ Sprint 3+ (Mois 2+): Features Avanc√©es
**Objectif**: UX et portabilit√© (apr√®s code stable et test√©)

- [ ] #6 GUI Desktop (1-2 semaines) - ROI 0.62
  - Prototype tkinter ou PyQt6
  - Interface moderne et r√©active
- [ ] #7 Support Multi-plateformes (2-3j) - ROI 0.63
  - Linux et macOS support
  - Tests sur chaque OS
- [ ] #8 Internationalisation i18n (1-2j) - ROI 0.60
  - Support FR/EN avec gettext
  - Extraction strings
- [ ] #12 Web App Client-Serveur (2-3 semaines) - ROI 0.62 (optionnel)
  - Backend FastAPI + Frontend React
  - Base PostgreSQL
  - D√©ploiement cloud

**Total**: 3-6 semaines
**R√©sultat**: Application accessible, portable, moderne

**Note**: Ces features ne seront impl√©ment√©es qu'APR√àS avoir r√©solu la dette technique (Sprint 1). Sinon, le refactoring de ces features sera tr√®s douloureux.

---

## üìù Notes de D√©veloppement

### Commandes Utiles

```bash
# Installation d√©pendances
pip install -r requirements.txt          # Production
pip install -r requirements-dev.txt      # D√©veloppement

# Tests
python test_db_fixes.py                  # Tests s√©curit√©/performance
pytest tests/ -v                         # Tous les tests
pytest tests/ --cov=src --cov-report=html  # Avec couverture

# Linting (√† ajouter)
pylint src/ --fail-under=8.0
black src/ --check
mypy src/

# Build
python build_app.py                      # Build executable
python create_package.py                 # Package portable

# Database
python cleanup_db.py                     # Backup et nettoyage
```

---

### M√©triques Cibles (Dette Technique First)

| M√©trique | Actuel | Sprint 0 ‚úÖ | Sprint 1 üî¥ (Dette Tech) | Sprint 2 üü° (Features) | Final |
|----------|--------|-------------|--------------------------|------------------------|-------|
| Test Coverage | ~5% | ~5% | **70%+** üî¥üî¥ | 75%+ | 80%+ |
| Largest File | 2,381 lignes | 2,381 lignes | **<500 lignes** üî¥üî¥üî¥ | <500 lignes | <400 lignes |
| SQL Injections | 0 ‚úÖ | 0 ‚úÖ | 0 ‚úÖ | 0 ‚úÖ | 0 ‚úÖ |
| Hardcoded Values | ~20 | **0** ‚úÖ | 0 ‚úÖ | 0 ‚úÖ | 0 ‚úÖ |
| Migrations BD | Non üî¥ | Non | **Alembic** üî¥ | Alembic ‚úÖ | Alembic ‚úÖ |
| Parse Time (all) | 30-60 min | 30-60 min | 30-60 min | **6-8 min** ‚ö° | <5 min |
| Build Time | ~2 min | ~2 min | ~2 min | **<1 min** | <30s |

**Philosophie Sprint 1**: Fondations solides (refactoring + tests + migrations) = V√©locit√© √©lev√©e ensuite

---

## üêõ Bugs Connus

### Bug #1: Cookie Click Coordinates ‚≠ê FIX√â dans T√¢che #4
**Fichier**: `parser.py:111`
**Priorit√©**: Haute
**Probl√®me**: `pyautogui.click(1661, 853)` ne fonctionne pas sur tous les √©crans
**Solution**: Voir T√¢che #4 - `accept_cookies_dynamic()`

### Bug #2: SyntaxWarning in parser.py ‚úÖ FIX√â
**Fichier**: `parser.py:111`
**Priorit√©**: Basse
**Warning**: `invalid escape sequence '\['`
**Status**: ‚úÖ **Corrig√©** (2025-11-27 dans T√¢che #2)
**Solution appliqu√©e**:
```python
# AVANT
elem.find_element(By.CLASS_NAME, "text-\[9px\]")

# APR√àS
elem.find_element(By.CLASS_NAME, r"text-\[9px\]")
```

---

## üí° Id√©es Futures (Backlog)

### En Cours de Planification
- **T√¢che #11** : Auto-Update BD (Service Windows) - Plus-value: 13, Difficult√©: 8, ROI: 1.63 ‚≠ê (D√âPEND de #4)
- **T√¢che #12** : Web App Client-Serveur - Plus-value: 21, Difficult√©: 34, ROI: 0.62

### Backlog Long Terme
- **API REST** - Exposer fonctionnalit√©s via API (Plus-value: 8, Difficult√©: 13)
- **Discord Bot** - Recommandations draft dans Discord (Plus-value: 5, Difficult√©: 8)
- **Overlay en jeu** - Affichage tier lists pendant draft (Plus-value: 13, Difficult√©: 21)
- **Machine Learning** - Pr√©diction winrate avanc√©e (Plus-value: 8, Difficult√©: 21)
- **Cloud Sync** - Synchronisation pools entre devices (Plus-value: 5, Difficult√©: 13)
- **Mobile App** - React Native (Plus-value: 8, Difficult√©: 21)
- **Monitoring Dashboard** - Sentry + Grafana pour prod (Plus-value: 5, Difficult√©: 8)

---

## ‚úÖ Completed Features

### Version 1.0.2 - Configuration Refactoring (2025-11-27)
- ‚úÖ **T√¢che #2: Extraction valeurs hardcod√©es** - config_constants.py avec 5 dataclasses
- ‚úÖ **Bug #2 Fix: SyntaxWarning parser.py** - Raw string literal pour regex
- ‚úÖ **Backward Compatibility** - @property decorators dans config.py
- ‚úÖ **TODO.md Update** - Approche "Dette Technique First" avec scores r√©vis√©s

### Version 1.0.1 - Security & Performance Update (2025-11-27)
- ‚úÖ **SQL Injection Fixes** - Toutes les requ√™tes param√©tr√©es
- ‚úÖ **Database Indexes** - 6 index pour performance (50-90% am√©lioration)
- ‚úÖ **Requirements Management** - requirements.txt + requirements-dev.txt
- ‚úÖ **Test Suite** - test_db_fixes.py pour s√©curit√© et index
- ‚úÖ **Documentation** - SECURITY_FIXES.md, CHANGELOG.md, AUDIT_REPORT.md

### Version 1.0.0 - Initial Release (2025-10-15)
- ‚úÖ **Tier List Generator** - Blind Pick & Counter Pick
- ‚úÖ **Code Refactoring** - champion normalization ‚Üí constants.py
- ‚úÖ **Real-time Draft Coach** - LCU integration
- ‚úÖ **Champion Pool Manager** - CRUD operations
- ‚úÖ **Team Builder** - Optimal trios/duos
- ‚úÖ **Standalone Distribution** - PyInstaller executable

---

**Derni√®re mise √† jour**: 2025-11-27
**Mainteneur**: @pj35
**Version**: 1.0.1
**M√©thode**: Agile/Scrum avec scores Fibonacci
